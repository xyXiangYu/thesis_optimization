

\chapter{The Classical and Training Approach}

The paper on hand focuses on using quasi-Newton and multi-shooting method for the Training Approach. In this chapter, we shortly introduce the Classical Approach first and then we discuss the Training Approach in greater detail. In the next chapter, we can introduce the quasi-Newton and multi-shooting method, and elaborate in detail how they can be used for the Training Approach. 



\section{The Classical Approach}

As stated in the introduction part, the classical approach is consistent with the $minmax$ approach, during which, two level optimization problems are solved. 

In the lower level, we solve an optimization problem ($max \  f(x,p)$) with respect to $p$, and in the upper level, we continue to find the best solution with respect to $x$, as shown in \ref{minmax}. In the case of the rocket car, the classical approach will be expressed in the following form

\begin{subequations}
	\begin{align}
		\underset{T, u(\cdot)}{min} \  \underset{ p \in \Omega_P, x(\cdot,p)}{max}  \ \   & \  T \\ 
		s.t.  & \ \ x = (x_1, x_2)   \label{ca_rc_x} \\ 
		& \ \  \dot{x} = T  \begin{pmatrix}  x_2(t;p) \\ u(t)-p   \end{pmatrix}, & \ t \in [0,1],  \label{ca_rc_partial} \\
		& \ \ x(0,p) = 0, \label{ca_rc_t0}\\
		& \ \ x_1(1;p) \geq 10, & \ for \ all \ p \in \Omega_P, \label{ca_rc_x1_t1} \\
		& \ \ x_2(t;p) \leq 4, & t \in [0,1], \ for \ all \ p \in \Omega_P,  \label{ca_rc_x2_tc} \\
		& \ \ x_2(1;p) \leq 0, & \ for \ all \ p \in \Omega_P, \label{ca_rc_x2_t1}  \\
		& \ \ T \geq 0, \\
		& \ \ u(t) \in [-10, 10], & t \in [0,1]. 
	\end{align}
	\label{ca_rc}
\end{subequations}

In the Classical Approach, the set of feasible controllable parameters and control functions are given by those $T$ and $u(\cdot)$, which yield feasible trajectories $x(\cdot, p)$ for all $p \in \Omega_P$. The value of the objective function in the lower level does not depend on $p$ and $x(\cdot, p)$. In other words, in this approach, the driver has no prior knowledge about the value of the parameter $p$ and gets no feedback during the process and has to set up the driving strategy in advance. 



\section{The Training Approach}
Contrast to the Classical Approach, in the Training Approach it is assumed that the driver of the rocket car is able to perform optmially for every $p$ because of a preceding training period. Thus the worst possible optimal performance is given by a solution of the problem

\begin{subequations}
	\begin{align}
	   \underset{p \in \Omega_P, T, u(\cdot), x(\cdot,p)}{max}  \ 	\underset{}{min} \   & \  T \\ 
		s.t.  & \ \ x = (x_1, x_2)   \label{ta_rc_x} \\ 
             & \ \  \dot{x} = T  \begin{pmatrix}  x_2(t;p) \\ u(t)-p   \end{pmatrix}, & \ t \in [0,1],  \label{ta_rc_partial} \\
& \ \ x(0,p) = 0, \label{ta_rc_t0}\\
& \ \ x_1(1;p) \geq 10, \label{ta_rc_x1_t1} \\
& \ \ x_2(t;p) \leq 4, & t \in [0,1], \label{ta_rc_x2_tc} \\
& \ \ x_2(1;p) \leq 0, \label{ta_rc_x2_t1}  \\
& \ \ T \geq 0, \\
& \ \ u(t) \in [-10, 10], & t \in [0,1]. 
	\end{align}
	\label{ca_rc}
\end{subequations}

The solution of the Training Approach in paper \cite{MatSch22} is given by a gradient-free method, which we are going to explain in the following.











%can assume that $p^0$ is a fixed value in the feasible uncertainty set $\Omega_P$

%The classical approach, aka, the robust optimization  is concerned with optimization problems which involes uncertainy parameters whose value is a priori unknown. 


% approach and the